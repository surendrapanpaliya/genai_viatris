{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06dbf41a",
   "metadata": {},
   "source": [
    "\n",
    "### LangChain Agents + MCP + Semantic Kernel\n",
    "\n",
    "This practical notebook teaches you how to build **agentic AI** for **Banking & Finance** using the latest:\n",
    "- **LangChain (v0.3+) Agents** — modern tool‑calling agents\n",
    "- **Model Context Protocol (MCP)** — bring external tools into your agent\n",
    "- **Semantic Kernel (SK)** — planners & orchestration with GPT‑class models (configure **GPT‑5** if available)\n",
    "\n",
    "> **Runs in Jupyter.** Cells are defensive: LLM sections gracefully skip if your API key isn't set.  \n",
    "> **Model note:** Set `OPENAI_MODEL=\"gpt-5\"` if your account has access; otherwise use a supported model like `gpt-4o` / `gpt-4o-mini`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d8c6f",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Environment & Versions\n",
    "\n",
    "Uncomment the `pip install` cell if you need to install/upgrade packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb05476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\n",
      "Platform: macOS-26.0.1-arm64-arm-64bit\n",
      "Loaded .env\n",
      "OPENAI_API_KEY set: True\n",
      "OPENAI_MODEL: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If needed, uncomment to install:\n",
    "# %pip install -U langchain langchain-core langchain-openai #                langgraph langchain-mcp-adapters mcp #                semantic-kernel python-dotenv\n",
    "\n",
    "import os, sys, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "\n",
    "# Optionally load secrets from a local .env\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"Loaded .env\")\n",
    "except Exception:\n",
    "    print(\"dotenv not used (ok)\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")  # set to \"gpt-5\" if you have access\n",
    "print(\"OPENAI_API_KEY set:\", bool(OPENAI_API_KEY))\n",
    "print(\"OPENAI_MODEL:\", OPENAI_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6892d16",
   "metadata": {},
   "source": [
    "\n",
    "## 1) LangChain Agents (v0.3) — Fundamentals\n",
    "\n",
    "We will build a **tool‑calling agent** with two BFSI‑flavoured tools:\n",
    "- `fx_rate(tool)`: returns a mocked FX rate (e.g., USD→INR).\n",
    "- `calc(tool)`: safely computes `a (+|-|*|/) b`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b2f539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools ready: fx_rate(), calc()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import TypedDict, Optional\n",
    "import ast, operator as op\n",
    "\n",
    "OPS = {ast.Add: op.add, ast.Sub: op.sub, ast.Mult: op.mul, ast.Div: op.truediv}\n",
    "\n",
    "def safe_eval_expr(expr: str) -> float:\n",
    "    node = ast.parse(expr, mode=\"eval\").body\n",
    "    def _eval(n):\n",
    "        if isinstance(n, ast.Num):  # type: ignore[attr-defined]\n",
    "            return float(n.n)\n",
    "        if isinstance(n, ast.BinOp) and type(n.op) in OPS:\n",
    "            return OPS[type(n.op)](_eval(n.left), _eval(n.right))\n",
    "        raise ValueError(\"Only + - * / with numbers supported.\")\n",
    "    return _eval(node)\n",
    "\n",
    "def fx_rate(pair: str = \"USD/INR\") -> str:\n",
    "    base, quote = pair.split(\"/\")\n",
    "    table = {(\"USD\",\"INR\"): 84.15, (\"EUR\",\"INR\"): 92.50, (\"GBP\",\"INR\"): 107.80}\n",
    "    val = table.get((base.upper(), quote.upper()))\n",
    "    return f\"{pair} ≈ {val} (mock)\" if val else f\"No mock rate for {pair}\"\n",
    "\n",
    "def calc(expr: str) -> str:\n",
    "    try:\n",
    "        return f\"{safe_eval_expr(expr):g}\"\n",
    "    except Exception as e:\n",
    "        return f\"calc error: {e}\"\n",
    "\n",
    "print(\"Tools ready: fx_rate(), calc()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d54c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fx_rate_tool', 'calc_tool']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def fx_rate_tool(pair: str = \"USD/INR\") -> str:\n",
    "    \"\"\"Return a mock FX rate for a currency pair like 'USD/INR'.\"\"\"\n",
    "    return fx_rate(pair)\n",
    "\n",
    "@tool\n",
    "def calc_tool(expr: str) -> str:\n",
    "    \"\"\"Compute a basic arithmetic expression like '12 + 5' or '100/4'.\"\"\"\n",
    "    return calc(expr)\n",
    "\n",
    "tools = [fx_rate_tool, calc_tool]\n",
    "[name for name in [t.name for t in tools]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce3dd4",
   "metadata": {},
   "source": [
    "\n",
    "### Build the agent (tool‑calling) and run a few tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce3479a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM enabled: True\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fx_rate_tool` with `{'pair': 'USD/INR'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mUSD/INR ≈ 84.15 (mock)\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: 84.15\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `calc_tool` with `{'expr': '125 * 8'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m1000\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: 1000\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final Answer: 84.15\n",
      "Final Answer: 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "USE_LLM = bool(OPENAI_API_KEY)\n",
    "print(\"LLM enabled:\", USE_LLM)\n",
    "\n",
    "if USE_LLM:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "    from langchain.tools.render import render_text_description\n",
    "\n",
    "    llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"You are a banking assistant. You can use tools.\\nTools:\\n{tools}\\n\\nTool names: {tool_names}\\nWhen done, reply ONLY as: Final Answer: <concise result>\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ])\n",
    "    prompt = prompt.partial(\n",
    "        tools=render_text_description(tools),\n",
    "        tool_names=\", \".join(t.name for t in tools),\n",
    "    )\n",
    "\n",
    "    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "    import nest_asyncio, asyncio\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    async def run_examples():\n",
    "        res1 = await executor.ainvoke({\"input\": \"What's the USD/INR FX rate?\" , \"agent_scratchpad\": []})\n",
    "        res2 = await executor.ainvoke({\"input\": \"Calculate 125 * 8\", \"agent_scratchpad\": []})\n",
    "        return res1, res2\n",
    "\n",
    "    r1, r2 = await run_examples()\n",
    "    print(r1.get(\"output\",\"\"))\n",
    "    print(r2.get(\"output\",\"\"))\n",
    "else:\n",
    "    print(\"⚠️ Set OPENAI_API_KEY to run the agent demo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a93030",
   "metadata": {},
   "source": [
    "\n",
    "## 2) MCP — Model Context Protocol (external tools)\n",
    "\n",
    "Create a tiny echo server and connect via **stdio**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196a8d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote echo_server.py — run it in another terminal:  python echo_server.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "server_code = '''\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Echo\")\n",
    "\n",
    "@mcp.tool()\n",
    "def reverse(text: str) -> str:\n",
    "    \"Return the reversed string.\"\n",
    "    return text[::-1]\n",
    "\n",
    "@mcp.tool()\n",
    "def upper(text: str) -> str:\n",
    "    \"Return the string in uppercase.\"\n",
    "    return text.upper()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "'''\n",
    "Path(\"echo_server.py\").write_text(server_code, encoding=\"utf-8\")\n",
    "print(\"Wrote echo_server.py — run it in another terminal:  python echo_server.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "507a711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `reverse` with `{'text': 'LangChain MCP'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPCM niahCgnaL\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `upper` with `{'text': 'PCM niahCgnaL'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPCM NIAHCGNAL\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: PCM NIAHCGNAL\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `upper` with `{'text': 'banking ai'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mBANKING AI\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: BANKING AI\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final Answer: PCM NIAHCGNAL\n",
      "Final Answer: BANKING AI\n"
     ]
    }
   ],
   "source": [
    "if USE_LLM:\n",
    "    from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "    from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "    from langchain.tools.render import render_text_description\n",
    "    from pathlib import Path\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    client = MultiServerMCPClient({\n",
    "        \"echo\": {\n",
    "            \"transport\": \"stdio\",\n",
    "            \"command\": \"python\",\n",
    "            \"args\": [str(Path(\"echo_server.py\").resolve())],\n",
    "        }\n",
    "    })\n",
    "    tools_mcp = await client.get_tools()\n",
    "\n",
    "    prompt2 = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"You can use MCP tools. Tools:\\n{tools}\\n\\nTool names: {tool_names}\\nWhen done, reply ONLY as: Final Answer: <result>\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ])\n",
    "    prompt2 = prompt2.partial(\n",
    "        tools=render_text_description(tools_mcp),\n",
    "        tool_names=\", \".join(t.name for t in tools_mcp),\n",
    "    )\n",
    "\n",
    "    llm2 = ChatOpenAI(model=OPENAI_MODEL, temperature=0)\n",
    "    agent2 = create_tool_calling_agent(llm=llm2, tools=tools_mcp, prompt=prompt2)\n",
    "    exec2 = AgentExecutor(agent=agent2, tools=tools_mcp, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "    resA = await exec2.ainvoke({\"input\": \"Reverse 'LangChain MCP'\", \"agent_scratchpad\": []})\n",
    "    resB = await exec2.ainvoke({\"input\": \"Make uppercase: banking ai\", \"agent_scratchpad\": []})\n",
    "    print(resA.get(\"output\",\"\"))\n",
    "    print(resB.get(\"output\",\"\"))\n",
    "else:\n",
    "    print(\"⚠️ Set OPENAI_API_KEY and run echo_server.py in another terminal to try MCP demo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943a638",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Semantic Kernel (SK) — planners with GPT‑class models (GPT‑5 if available)\n",
    "\n",
    "Minimal pattern (adjust imports per your SK version).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d505df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Kernel imported.\n",
      "⚠️ SK demo skipped or adjust imports for your SK version: 'Kernel' object has no attribute 'add_text_completion_service'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import semantic_kernel as sk\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    print(\"Semantic Kernel imported.\")\n",
    "\n",
    "    kernel = sk.Kernel()\n",
    "    api_key = OPENAI_API_KEY or \"missing\"\n",
    "    service = OpenAIChatCompletion(OPENAI_MODEL, api_key=api_key)\n",
    "    kernel.add_text_completion_service(\"openai\", service)\n",
    "\n",
    "    goal = \"Summarize RBI policy changes impacting home loans in 3 bullet points.\"\n",
    "    prompt = f\"Plan steps to achieve this goal, then produce the final 3-bullet summary.\\nGoal: {goal}\"\n",
    "    result = await kernel.complete_text_async(prompt)\n",
    "    print(\"SK Result:\\n\", result)\n",
    "except Exception as e:\n",
    "    print(\"⚠️ SK demo skipped or adjust imports for your SK version:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa26c9",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Router: plan tasks → SK, operational tasks → Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3857dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fx_rate_tool` with `{'pair': 'USD/INR'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `calc_tool` with `{'expr': '12 * 9'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mUSD/INR ≈ 84.15 (mock)\u001b[0m\u001b[33;1m\u001b[1;3m108\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: USD/INR ≈ 84.15 (mock), 108\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final Answer: USD/INR ≈ 84.15 (mock), 108\n",
      "Planner route unavailable: 'Kernel' object has no attribute 'complete_text_async'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Request:\n",
    "    text: str\n",
    "\n",
    "async def handle_request(req: Request):\n",
    "    txt = req.text.strip()\n",
    "    if txt.lower().startswith(\"plan:\"):\n",
    "        try:\n",
    "            import semantic_kernel as sk  # ensure available\n",
    "            return \"Planner route:\\n\" + (await kernel.complete_text_async(txt))\n",
    "        except Exception as e:\n",
    "            return f\"Planner route unavailable: {e}\"\n",
    "    else:\n",
    "        if not USE_LLM:\n",
    "            return \"Agent route blocked: set OPENAI_API_KEY.\"\n",
    "        out = await executor.ainvoke({\"input\": txt, \"agent_scratchpad\": []})\n",
    "        return out.get(\"output\",\"\")\n",
    "\n",
    "print(await handle_request(Request(\"What is USD/INR and then compute 12 * 9?\")))\n",
    "print(await handle_request(Request(\"plan: Draft a 2-step plan to compare two RBI circulars.\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2babb4",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Next Steps\n",
    "- Add **LangSmith** tracing & governance.\n",
    "- Replace mocks with real BFSI systems (rates API, risk engines).\n",
    "- Combine with **LangGraph** for multi‑step flows and decision routing.\n",
    "- Package with **FastAPI** and deploy (Azure/AWS).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
